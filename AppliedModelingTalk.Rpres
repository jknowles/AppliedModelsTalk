Applied Modeling Talk
========================================================
author: Jared Knowles
date: October, 2013

Overview
===============

- What are statistical models?
- What is applied modeling?
- What to keep in mind?
- Why is this important?

What is a model?
===============================

- An abstraction from reality
- What features does it have?
- What purpose does it serve?

<img src="img/pictureaf1art1.jpg" title="747 Model" alt="747Model" style="display: block; margin: auto;" />

Is this  a model?
===============================

<img src="img/dalek_blueprint.jpg" title="Dalek Model" alt="747Model" style="display: block; margin: auto;" />


What is a statistical model?
===============================

- "All models are wrong, some models are useful"
- Being wrong is a **feature of a statistical model**, the goal is to explain 
as much data as possible with as few variables as possible
- Statistical models are mathematical summaries of correlations and probabilities
- The most common form is linear regression models


Do machines really learn?
========================================================

Applied modeling goes by many names: statistical learning, machine learning, and 
data mining. 

The key differences between applied modeling and statistical inference are:

- Emphasis on predictive validity
- De-emphasis on parameter values
- Test and training data
- Measures of fit

Applied Models and Inference
========================================================

Applied modeling and inferential statistics share many of the same concepts:

- Regression estimation
- Concerns about representative of data and samples
- Fear of outliers
- Robustness and sensitivity

```{r, echo=FALSE, fig.align='center', fig.height=3.5, fig.width=8}
library(eeptools)
qplot(speed, dist, data=cars) + theme_dpi() + geom_smooth(method='lm', se=FALSE) +
  geom_smooth(method="loess", color=I("purple"), se=FALSE)+
  annotate("segment", x=24, xend=24, y=120, yend=77, color="red", lty = 3, size=1.1)

```


Supervised vs. Unsupervised Learning
===========================================================

A key distinction in statistical learning is that between **supervised** and 
**unsupervised** techniques. 

- **supervised** - relationship between inputs and outputs is being explored
- **unsupervised** - the relationship among inputs is being explored, no output

We will focus on **supervised** learning for the most part in this talk. 

```{r clusters, echo=FALSE, results='hide', fig.align='center', fig.height=3, fig.width=4}
x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
           matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
colnames(x) <- c("x", "y")
cl <- kmeans(x, 2)
plot(x, col = cl$cluster)
points(cl$centers, col = 1:2, pch = 8, cex = 2)
# 
# # sum of squares
# ss <- function(x) sum(scale(x, scale = FALSE)^2)
# 
# ## cluster centers "fitted" to each obs.:
# fitted.x <- fitted(cl);  head(fitted.x)
# resid.x <- x - fitted(cl)
# 
# **Unsupervised** techniques like cluster, principal components, factor, and 
# latent variable analysis can be very useful!
```


Statistical Modeling
=======================================================

It is useful to remember that in statistical modeling, in the **supervised** case, we are looking at the following relationship:

$$ \hat{Y} = \hat{f}(X) $$

In this case $\hat{f}$ represents our estimate of the function that links $X$ and 
$Y$. In traditional linear modeling, $\hat{f}$ takes the form:

$$ \hat{Y} = \alpha + \beta(X) + \epsilon $$

However, there exist limitless alternative $\hat{f}$ which we can explore. Applied modeling techniques help us expand the $\hat{f}$ space we search within.

How do we choose f?
===================================================

Choosing $f$ is about tradeoffs, the most obvious is between flexibility and 
interpretability.

```{r, echo=FALSE, fig.align='center', fig.width=11.5}
library(eeptools)
x    <- c(1, 2, 3, 4, 5, 6, 7, 8)
y    <- c(14, 12, 10, 8, 6, 4, 2, 0)

jit <- function(x) x + runif(1, min=-.5, max=.5)
x <- sapply(x, jit)
y <- sapply(y, jit)

labs <- c("Lasso", "Subset Selection", "Least Squares", 
          "Generalized Additive Models", "KNN", "Trees", "Bagging, Boosting", 
          "Support Vector Machines")

qplot(x, y, geom='text', label=labs) + theme_dpi() + 
  scale_x_continuous("Flexibility", limits=c(min(x) - 0.5, max(x) + 0.5)) +
  scale_y_continuous("Interpretability", limits=c(min(y) - 0.5, max(y) + 0.5)) +
  labs(title="Functional Forms and Tradeoffs") + 
  theme(axis.text=element_blank(), axis.ticks=element_blank())
```


Why the Difference?
========================================================

Applied Models:

- Provide information to users about what to expect given certain data
- Goals for the model are defined by the needs of the users

***

Inferential Models: 

- Seek to learn about the relationships in the data at hand
- Focused on understanding patterns in the current data


Some Vocabulary
========================================================

- Training data
- Test data


***

- Data the model is fit to
- Data the model is applied to, but not fit to, to evaluate model fit

The Challenge
=================================

- When using a statistical model to make predictions we have to think clearly 
about the data we use to build the model, and the data we will be making 
predictions about
- We may build a model with high **internal validity** for the data at hand, 
but that data may not be representative of the data the model will apply to
- We call this the **training error** and the **test error**
- In inferential statistics we often seek to reduce **training error** and not 
concern ourselves with **test error**


A Trivial Example
===============================

Consider the following:

```{r, echo=FALSE, results='hide', fig.align='center', fig.width=9}
library(MASS)
library(Matrix)
set.seed(8742)
N <- 1000
J <- 4 ### Number of predictors (including intercept)
G <- 5 ### Number of Multilevel Groups
X <- matrix(rnorm(N*J,0,2),N,J)
X[,1] <- 1
Sigma <- matrix(runif(J*J,-1,1),J,J)
Sigma <- nearPD(Sigma)$mat
#diag(Sigma) <- runif(J,1,5)
gamma <- runif(J,-1.2,1.2)
beta <- matrix(NA,G,J)
for (g in 1:G) {beta[g,] <- mvrnorm(1, gamma, Sigma)}
m <- sample(1:G, N, replace=TRUE) ### Multilevel group indicator
y <- rowSums(beta[m,] * X) + rnorm(N,0,.2)

plotdf <- cbind(X, m, y)
plotdf <- as.data.frame(plotdf)

mod1 <- lm(y ~ V2 + V3 + V4 + factor(m), data=plotdf[plotdf$m>3,])
mod2 <- lm(y ~ V2 + V3 + V4 + factor(m), data=plotdf[plotdf$m<=3,])

mod1.plot <- fortify(mod1)
mod2.plot <- fortify(mod2)

plotdf$sample <- NA
plotdf$sample[plotdf$m>3] <- "A"
plotdf$sample[plotdf$m<=3] <- "B"


qplot(V2, y, data=plotdf[plotdf$m>3,]) + 
  geom_smooth(data=mod1.plot, aes(x=V2, y=.fitted), se=FALSE, size=I(1.1),
              method=lm) +
  coord_cartesian(xlim=c(-7,7), ylim=c(-12,13)) +
  theme_dpi()

```

Consider the Test Data
=========================

```{r, echo=FALSE, results='hide', fig.align='center', fig.width=9}
qplot(V2, y, data=plotdf[plotdf$m<=3,], alpha=I(0.6)) + 
  geom_smooth(data=mod1.plot, aes(x=V2, y=.fitted), se=FALSE, size=I(1.6),
              method=lm) +
    coord_cartesian(xlim=c(-7,7), ylim=c(-12,13)) +
  geom_smooth(linetype=2, se=FALSE, size=I(1.6), color=I("purple"))+
  theme_dpi()
```

Consider the Pooled Data
==========================

```{r, echo=FALSE, results='hide', fig.align='center', fig.width=9}
qplot(V2, y, data=plotdf, color=sample) + geom_smooth(method=lm, aes(group=1))+
  geom_smooth(data=mod1.plot, aes(x=V2, y=.fitted, color=NULL), 
              se=FALSE, size=I(1.1),method=lm) +  
     geom_smooth(data=mod2.plot, aes(x=V2, y=.fitted, color=NULL), 
              se=FALSE, size=I(1.1),method=lm) + 
      coord_cartesian(xlim=c(-7,7), ylim=c(-12,13)) +
  theme_dpi()

```

What do we learn?
=============================

- The data was generated the same


When Could this Matter: Stocks?
=================================

```{r, echo=FALSE, results='hide', fig.align='center', fig.width=9}
library('quantmod')
library('lubridate')

getSymbols("AAPL")
AAPL$year <- year(index(AAPL))
AAPL$yearL <- lag(AAPL$year)
AAPL$yearSTART <- 0
AAPL$yearSTART[AAPL$year - AAPL$yearL > 0] <- 1
AAPL$yearL <- NULL
AAPL$lag <- lag(AAPL$AAPL.Adjusted)
AAPL$lag2 <- lag(AAPL$AAPL.Adjusted, 2)
AAPL$lag3 <- lag(AAPL$AAPL.Adjusted, 3)
AAPL$lag30 <- lag(AAPL$AAPL.Adjusted, 30)
AAPL$lag90 <- lag(AAPL$AAPL.Adjusted, 90)

plotdf <- as.data.frame(AAPL)
plotdf$time <- row.names(plotdf)
plotdf <- plotdf[300:1700,]
plotdf$group <- NA
plotdf$group[50:300] <- 1
plotdf$group[300:500] <- 2

plotdf$time2 <- as.factor(plotdf$time)
plotdf$time2 <- as.numeric(plotdf$time2)

pred.con <- loess.control(surface="direct")

model1 <- loess(AAPL.Adjusted ~ time2 + lag + lag30, 
                data=plotdf[plotdf$group==1,], 
                control=pred.con, parametric=c("lag"))

xrange <- range(plotdf$time2)
xseq <- seq(from=xrange[1], to=xrange[2], length=nrow(plotdf))
pred <- predict(model1, newdata = data.frame(time2 = xseq, lag=plotdf$lag, 
                                             lag30 = plotdf$lag30,
                                             lag90 = plotdf$lag90), se=TRUE)
y = pred$fit
ci <- pred$se.fit * qt(0.95 / 2 + .5, pred$df)
ymin = y - ci
ymax = y + ci
loess.DF <- data.frame(x = xseq, y) #, ymin, ymax, se = pred$se.fit)

model2 <- loess(AAPL.Adjusted ~ time2 + lag + lag30, 
                data=plotdf[500:800,], 
                control=pred.con,  parametric=c("lag"))

xrange <- range(plotdf$time2)
xseq <- seq(from=xrange[1], to=xrange[2], length=nrow(plotdf))
pred <- predict(model2, newdata = data.frame(time2 = xseq, lag=plotdf$lag, 
                                             lag30 = plotdf$lag30,
                                             lag90 = plotdf$lag90), se=TRUE)
y = pred$fit
ci <- pred$se.fit * qt(0.95 / 2 + .5, pred$df)
ymin = y - ci
ymax = y + ci
loess.DF2 <- data.frame(x = xseq, y)


idx1 <- plotdf$time2[plotdf$yearSTART==1][5]
idx2 <- plotdf$time2[plotdf$yearSTART==1][4]
idx3 <- plotdf$time2[plotdf$yearSTART==1][3]


qplot(time, AAPL.Adjusted, data = plotdf, geom='line', group=1) +
     coord_cartesian(xlim=c(0,1400), ylim=c(60,700)) +
  geom_vline(xintercept=idx1, color="red", linetype=3) + 
  geom_vline(xintercept=idx2, color="red", linetype=3) + 
  geom_vline(xintercept=idx3, color="red", linetype=3) + 
  theme_dpi()+
  theme(axis.text.x=element_blank(), axis.ticks=element_blank(), 
        panel.grid.major.x = element_blank(), 
        panel.grid.minor.x = element_blank()) 

```


Forecasting Apple Stock Could be Useful
===========================================

```{r, echo=FALSE, results='hide', fig.align='center', fig.width=9}

qplot(time, AAPL.Adjusted, data = plotdf, geom='line', group=1) +
  geom_smooth(aes_auto(loess.DF),  data=loess.DF, stat="identity", se=FALSE) +
     coord_cartesian(xlim=c(0,800), ylim=c(60,700)) +
  geom_vline(xintercept=idx1, color="red", linetype=3) + 
  geom_vline(xintercept=idx2, color="red", linetype=3) + 
  geom_vline(xintercept=idx3, color="red", linetype=3) + 
  theme_dpi()+
  theme(axis.text.x=element_blank(), axis.ticks=element_blank(), 
        panel.grid.major.x = element_blank(), 
        panel.grid.minor.x = element_blank()) 

```

Forecasts Are Tricky
========================

```{r, echo=FALSE, results='hide', fig.align='center', fig.width=9}
qplot(time, AAPL.Adjusted, data = plotdf, geom='line', group=1) +
  geom_smooth(aes_auto(loess.DF2),  data=loess.DF2, stat="identity", 
              se=FALSE, color="purple") +
     coord_cartesian(xlim=c(500,1400), ylim=c(60,700)) +
  geom_vline(xintercept=idx1, color="red", linetype=3) + 
  geom_vline(xintercept=idx2, color="red", linetype=3) + 
  geom_vline(xintercept=idx3, color="red", linetype=3) + 
  theme_dpi()+
  theme(axis.text.x=element_blank(), axis.ticks=element_blank(), 
        panel.grid.major.x = element_blank(), 
        panel.grid.minor.x = element_blank()) 

```

The Further We Get From The Training Data...
================================================


```{r, echo=FALSE, results='hide', fig.align='center', fig.width=9}
qplot(time, AAPL.Adjusted, data = plotdf, geom='line', group=1) +
  geom_smooth(aes_auto(loess.DF),  data=loess.DF, stat="identity", se=FALSE) +
  geom_smooth(aes_auto(loess.DF2),  data=loess.DF2, stat="identity", 
              se=FALSE, color="purple") +
     coord_cartesian(xlim=c(0,1400), ylim=c(60,700)) +
  geom_vline(xintercept=idx1, color="red", linetype=3) + 
  geom_vline(xintercept=idx2, color="red", linetype=3) + 
  geom_vline(xintercept=idx3, color="red", linetype=3) + 
  theme_dpi()+
  theme(axis.text.x=element_blank(), axis.ticks=element_blank(), 
        panel.grid.major.x = element_blank(), 
        panel.grid.minor.x = element_blank()) 

```


Overfit
=====================

- Training data can lead to model overfit